/*
 * opensearch-client
 *
 * Rust Client for OpenSearch
 *
 * The version of the OpenAPI document: 3.1.0
 * Contact: alberto.paro@gmail.com
 * Generated by Paro OpenAPI Generator
 */
use bon::bon;

use reqwest;
use std::sync::Arc;
use serde::{Deserialize, Serialize, de::Error as OtherError};
use crate::{apis::ResponseContent, models};
use super::{Error, configuration};
use crate::apis::ContentType;
use crate::*;


#[async_trait]
pub trait KnnApi: Send + Sync {


    /// GET /_plugins/_knn/{node_id}/stats/{stat}///
    /// Provides information about the current status of the k-NN plugin.
    async fn stats(&self, params: StatsParams) -> Result<crate::knn::Stats, Error>;

    /// GET /_plugins/_knn/models/{model_id}///
    /// Used to retrieve information about models present in the cluster.
    async fn get_model(&self, params: GetModelParams) -> Result<crate::knn::GetModelResponse, Error>;

    /// POST /_plugins/_knn/models/{model_id}/_train///
    /// Create and train a model that can be used for initializing k-NN native library indexes during indexing.
    async fn train_model(&self, params: TrainModelParams) -> Result<crate::knn::TrainModelResponse, Error>;

    /// DELETE /_plugins/_knn/models/{model_id}///
    /// Used to delete a particular model in the cluster.
    async fn delete_model(&self, params: DeleteModelParams) -> Result<crate::knn::DeletedModel, Error>;

    /// GET /_plugins/_knn/warmup/{index}///
    /// Preloads native library files into memory, reducing initial search latency for specified indexes.
    async fn warmup(&self, params: WarmupParams) -> Result<crate::common::ShardsOperationResponseBase, Error>;

    /// POST /_plugins/_knn/models/_search///
    /// Use an OpenSearch query to search for models in the index.
    async fn search_models(&self, params: SearchModelsParams) -> Result<crate::core::search::ResponseBody, Error>;
}

pub struct KnnApiClient {
    configuration: Arc<crate::Configuration>
}

impl KnnApiClient {
    pub fn new(configuration: Arc<crate::Configuration>) -> Self {
        Self { configuration }
    }
}


/// Struct for passing parameters to the method [`stats`]
#[derive(Clone, Debug)]
#[cfg_attr(feature = "bon", derive(::bon::Builder))]
pub struct StatsParams {
      /// A duration. Units can be `nanos`, `micros`, `ms` (milliseconds), `s` (seconds), `m` (minutes), `h` (hours) and
  /// `d` (days). Also accepts "0" without a unit and "-1" to indicate an unspecified value.
    pub timeout: Option<String>,
      /// No description available
    pub error_trace: Option<bool>,
      /// No description available
    pub filter_path: Option<common::FilterPath>,
      /// No description available
    pub human: Option<bool>,
      /// No description available
    pub node_id: String,
      /// No description available
    pub pretty: Option<bool>,
      /// No description available
    pub source: Option<String>,
      /// No description available
    pub stat: String,
}
/// Struct for passing parameters to the method [`get_model`]
#[derive(Clone, Debug)]
#[cfg_attr(feature = "bon", derive(::bon::Builder))]
pub struct GetModelParams {
      /// No description available
    pub error_trace: Option<bool>,
      /// No description available
    pub filter_path: Option<common::FilterPath>,
      /// No description available
    pub human: Option<bool>,
      /// No description available
    pub model_id: String,
      /// No description available
    pub pretty: Option<bool>,
      /// No description available
    pub source: Option<String>,
}
/// Struct for passing parameters to the method [`train_model`]
#[derive(Clone, Debug)]
#[cfg_attr(feature = "bon", derive(::bon::Builder))]
pub struct TrainModelParams {
    
    pub train_model: knn::TrainModel,
      /// No description available
    pub error_trace: Option<bool>,
      /// No description available
    pub filter_path: Option<common::FilterPath>,
      /// No description available
    pub human: Option<bool>,
      /// No description available
    pub model_id: String,
      /// No description available
    pub pretty: Option<bool>,
      /// No description available
    pub source: Option<String>,
      /// Preferred node to execute training.
    pub preference: Option<String>,
}
/// Struct for passing parameters to the method [`delete_model`]
#[derive(Clone, Debug)]
#[cfg_attr(feature = "bon", derive(::bon::Builder))]
pub struct DeleteModelParams {
      /// No description available
    pub error_trace: Option<bool>,
      /// No description available
    pub filter_path: Option<common::FilterPath>,
      /// No description available
    pub human: Option<bool>,
      /// No description available
    pub model_id: String,
      /// No description available
    pub pretty: Option<bool>,
      /// No description available
    pub source: Option<String>,
}
/// Struct for passing parameters to the method [`warmup`]
#[derive(Clone, Debug)]
#[cfg_attr(feature = "bon", derive(::bon::Builder))]
pub struct WarmupParams {
      /// No description available
    pub error_trace: Option<bool>,
      /// No description available
    pub filter_path: Option<common::FilterPath>,
      /// No description available
    pub human: Option<bool>,
      /// No description available
    pub index: String,
      /// No description available
    pub pretty: Option<bool>,
      /// No description available
    pub source: Option<String>,
}
/// Struct for passing parameters to the method [`search_models`]
#[derive(Clone, Debug)]
#[cfg_attr(feature = "bon", derive(::bon::Builder))]
pub struct SearchModelsParams {
    
    pub search_models: knn::SearchModels,
      /// A duration. Units can be `nanos`, `micros`, `ms` (milliseconds), `s` (seconds), `m` (minutes), `h` (hours) and
  /// `d` (days). Also accepts "0" without a unit and "-1" to indicate an unspecified value.
    pub scroll: Option<String>,
      /// A duration. Units can be `nanos`, `micros`, `ms` (milliseconds), `s` (seconds), `m` (minutes), `h` (hours) and
  /// `d` (days). Also accepts "0" without a unit and "-1" to indicate an unspecified value.
    pub timeout: Option<String>,
      /// How many suggestions to return in response.
    pub suggest_size: Option<i32>,
      /// Indicate if an error should be returned if there is a partial search failure or timeout.
    pub allow_partial_search_results: Option<bool>,
      /// Indicate if the number of documents that match the query should be tracked.
    pub track_total_hits: Option<bool>,
      /// Indicates whether `hits.total` should be rendered as an integer or an object in the rest search response.
    pub rest_total_hits_as_int: Option<bool>,
      /// Indicates whether network round-trips should be minimized as part of cross-cluster search requests execution.
    pub ccs_minimize_roundtrips: Option<bool>,
      /// No description available
    pub source_excludes: Option<Vec<String>>,
      /// No description available
    pub source_includes: Option<Vec<String>>,
      /// No description available
    pub docvalue_fields: Option<Vec<String>>,
      /// No description available
    pub error_trace: Option<bool>,
      /// No description available
    pub filter_path: Option<common::FilterPath>,
      /// No description available
    pub human: Option<bool>,
      /// No description available
    pub pretty: Option<bool>,
      /// No description available
    pub routing: Option<common::Routing>,
      /// No description available
    pub sort: Option<Vec<String>>,
      /// No description available
    pub source: Option<String>,
      /// No description available
    pub stats: Option<Vec<String>>,
      /// No description available
    pub stored_fields: Option<Vec<String>>,
      /// Number of hits to return.
    pub size: Option<i32>,
      /// Query in the Lucene query string syntax.
    pub q: Option<String>,
      /// Search operation type.
    pub search_type: Option<String>,
      /// Specifies the type of index that wildcard expressions can match. Supports comma-separated values.
    pub expand_wildcards: Option<common::ExpandWildcards>,
      /// Specify if request cache should be used for this request or not, defaults to index level setting.
    pub request_cache: Option<bool>,
      /// Specify suggest mode.
    pub suggest_mode: Option<String>,
      /// Specify the node or shard the operation should be performed on.
    pub preference: Option<String>,
      /// Specify whether aggregation and suggester names should be prefixed by their respective types in the response.
    pub typed_keys: Option<bool>,
      /// Specify whether format-based query failures (such as providing text to a numeric field) should be ignored.
    pub lenient: Option<bool>,
      /// Specify whether to return detailed information about score computation as part of a hit.
    pub explain: Option<bool>,
      /// Specify whether to return sequence number and primary term of the last modification of each hit.
    pub seq_no_primary_term: Option<bool>,
      /// Specify whether wildcard and prefix queries should be analyzed.
    pub analyze_wildcard: Option<bool>,
      /// Specify which field to use for suggestions.
    pub suggest_field: Option<String>,
      /// Starting offset.
    pub from: Option<i32>,
      /// The analyzer to use for the query string.
    pub analyzer: Option<String>,
      /// The default operator for query string query (AND or OR).
    pub default_operator: Option<String>,
      /// The field to use as default where no field prefix is given in the query string.
    pub df: Option<String>,
      /// The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early.
    pub terminate_after: Option<i32>,
      /// The number of concurrent shard requests per node this search executes concurrently. This value should be used to limit the impact of the search on the cluster in order to limit the number of concurrent shard requests.
    pub max_concurrent_shard_requests: Option<i32>,
      /// The number of shard results that should be reduced at once on the coordinating node. This value should be used as a protection mechanism to reduce the memory overhead per search request if the potential number of shards in the request can be large.
    pub batched_reduce_size: Option<i32>,
      /// The source text for which the suggestions should be returned.
    pub suggest_text: Option<String>,
      /// Threshold that enforces a pre-filter round-trip to prefilter search shards based on query rewriting if the number of shards the search request expands to exceeds the threshold. This filter round-trip can limit the number of shards significantly if for instance a shard can not match any documents based on its rewrite method, that is if date filters are mandatory to match but the shard bounds and the query are disjoint.
    pub pre_filter_shard_size: Option<i32>,
      /// Whether specified concrete indexes should be ignored when unavailable (missing or closed).
    pub ignore_unavailable: Option<bool>,
      /// Whether specified concrete, expanded or aliased indexes should be ignored when throttled.
    pub ignore_throttled: Option<bool>,
      /// Whether to calculate and return scores even if they are not used for sorting.
    pub track_scores: Option<bool>,
      /// Whether to ignore if a wildcard indexes expression resolves into no concrete indexes. (This includes `_all` string or when no indexes have been specified).
    pub allow_no_indices: Option<bool>,
      /// Whether to return document version as part of a hit.
    pub version: Option<bool>,
}

#[async_trait]
impl KnnApi for KnnApiClient {
///
      /// Provides information about the current status of the k-NN plugin.
    async fn stats(&self, params: StatsParams) -> Result<crate::knn::Stats, Error> {
        let StatsParams {
            timeout,
            error_trace,
            filter_path,
            human,
            node_id,
            pretty,
            source,
            stat,
        } = params;
    
        let local_var_configuration = &self.configuration;

        let local_var_client = &local_var_configuration.client;

        let local_var_uri_str = format!("{}_plugins/_knn/{node_id}/stats/{stat}", local_var_configuration.base_path, node_id=node_id, stat=stat);
        let mut local_var_req_builder = local_var_client.request(reqwest::Method::GET, local_var_uri_str.as_str());


    if let Some(ref local_var_str) = timeout {
        local_var_req_builder = local_var_req_builder.query(&[("timeout", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = error_trace {
        local_var_req_builder = local_var_req_builder.query(&[("error_trace", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = filter_path {
        local_var_req_builder = local_var_req_builder.query(&[("filter_path", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = pretty {
        local_var_req_builder = local_var_req_builder.query(&[("pretty", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source {
        local_var_req_builder = local_var_req_builder.query(&[("source", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = human {
        local_var_req_builder = local_var_req_builder.query(&[("human", &local_var_str.to_string())]);
    }







        let local_var_req = local_var_req_builder.build()?;
        let local_var_resp = local_var_client.execute(local_var_req).await?;

        let local_var_status = local_var_resp.status();
        let local_var_content = local_var_resp.text().await?;

        if !local_var_status.is_client_error() && !local_var_status.is_server_error() {
            
            serde_json::from_str(&local_var_content).map_err(Error::from)
            
            
        } else {
            let local_var_error = ResponseContent {
                status: local_var_status,
                content: local_var_content,
            };
            Err(Error::ApiError(local_var_error))
        }
    }///
      /// Used to retrieve information about models present in the cluster.
    async fn get_model(&self, params: GetModelParams) -> Result<crate::knn::GetModelResponse, Error> {
        let GetModelParams {
            error_trace,
            filter_path,
            human,
            model_id,
            pretty,
            source,
        } = params;
    
        let local_var_configuration = &self.configuration;

        let local_var_client = &local_var_configuration.client;

        let local_var_uri_str = format!("{}_plugins/_knn/models/{model_id}", local_var_configuration.base_path, model_id=model_id);
        let mut local_var_req_builder = local_var_client.request(reqwest::Method::GET, local_var_uri_str.as_str());


    if let Some(ref local_var_str) = pretty {
        local_var_req_builder = local_var_req_builder.query(&[("pretty", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = human {
        local_var_req_builder = local_var_req_builder.query(&[("human", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = error_trace {
        local_var_req_builder = local_var_req_builder.query(&[("error_trace", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source {
        local_var_req_builder = local_var_req_builder.query(&[("source", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = filter_path {
        local_var_req_builder = local_var_req_builder.query(&[("filter_path", &local_var_str.to_string())]);
    }







        let local_var_req = local_var_req_builder.build()?;
        let local_var_resp = local_var_client.execute(local_var_req).await?;

        let local_var_status = local_var_resp.status();
        let local_var_content = local_var_resp.text().await?;

        if !local_var_status.is_client_error() && !local_var_status.is_server_error() {
            
            serde_json::from_str(&local_var_content).map_err(Error::from)
            
            
        } else {
            let local_var_error = ResponseContent {
                status: local_var_status,
                content: local_var_content,
            };
            Err(Error::ApiError(local_var_error))
        }
    }///
      /// Create and train a model that can be used for initializing k-NN native library indexes during indexing.
    async fn train_model(&self, params: TrainModelParams) -> Result<crate::knn::TrainModelResponse, Error> {
        let TrainModelParams {
            train_model,
            error_trace,
            filter_path,
            human,
            model_id,
            pretty,
            source,
            preference,
        } = params;
    
        let local_var_configuration = &self.configuration;

        let local_var_client = &local_var_configuration.client;

        let local_var_uri_str = format!("{}_plugins/_knn/models/{model_id}/_train", local_var_configuration.base_path, model_id=model_id);
        let mut local_var_req_builder = local_var_client.request(reqwest::Method::POST, local_var_uri_str.as_str());


    if let Some(ref local_var_str) = preference {
        local_var_req_builder = local_var_req_builder.query(&[("preference", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = error_trace {
        local_var_req_builder = local_var_req_builder.query(&[("error_trace", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = human {
        local_var_req_builder = local_var_req_builder.query(&[("human", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = filter_path {
        local_var_req_builder = local_var_req_builder.query(&[("filter_path", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = pretty {
        local_var_req_builder = local_var_req_builder.query(&[("pretty", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source {
        local_var_req_builder = local_var_req_builder.query(&[("source", &local_var_str.to_string())]);
    }






    local_var_req_builder = local_var_req_builder.json(&train_model);

        let local_var_req = local_var_req_builder.build()?;
        let local_var_resp = local_var_client.execute(local_var_req).await?;

        let local_var_status = local_var_resp.status();
        let local_var_content = local_var_resp.text().await?;

        if !local_var_status.is_client_error() && !local_var_status.is_server_error() {
            
            serde_json::from_str(&local_var_content).map_err(Error::from)
            
            
        } else {
            let local_var_error = ResponseContent {
                status: local_var_status,
                content: local_var_content,
            };
            Err(Error::ApiError(local_var_error))
        }
    }///
      /// Used to delete a particular model in the cluster.
    async fn delete_model(&self, params: DeleteModelParams) -> Result<crate::knn::DeletedModel, Error> {
        let DeleteModelParams {
            error_trace,
            filter_path,
            human,
            model_id,
            pretty,
            source,
        } = params;
    
        let local_var_configuration = &self.configuration;

        let local_var_client = &local_var_configuration.client;

        let local_var_uri_str = format!("{}_plugins/_knn/models/{model_id}", local_var_configuration.base_path, model_id=model_id);
        let mut local_var_req_builder = local_var_client.request(reqwest::Method::DELETE, local_var_uri_str.as_str());


    if let Some(ref local_var_str) = pretty {
        local_var_req_builder = local_var_req_builder.query(&[("pretty", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = error_trace {
        local_var_req_builder = local_var_req_builder.query(&[("error_trace", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = human {
        local_var_req_builder = local_var_req_builder.query(&[("human", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source {
        local_var_req_builder = local_var_req_builder.query(&[("source", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = filter_path {
        local_var_req_builder = local_var_req_builder.query(&[("filter_path", &local_var_str.to_string())]);
    }







        let local_var_req = local_var_req_builder.build()?;
        let local_var_resp = local_var_client.execute(local_var_req).await?;

        let local_var_status = local_var_resp.status();
        let local_var_content = local_var_resp.text().await?;

        if !local_var_status.is_client_error() && !local_var_status.is_server_error() {
            
            serde_json::from_str(&local_var_content).map_err(Error::from)
            
            
        } else {
            let local_var_error = ResponseContent {
                status: local_var_status,
                content: local_var_content,
            };
            Err(Error::ApiError(local_var_error))
        }
    }///
      /// Preloads native library files into memory, reducing initial search latency for specified indexes.
    async fn warmup(&self, params: WarmupParams) -> Result<crate::common::ShardsOperationResponseBase, Error> {
        let WarmupParams {
            error_trace,
            filter_path,
            human,
            index,
            pretty,
            source,
        } = params;
    
        let local_var_configuration = &self.configuration;

        let local_var_client = &local_var_configuration.client;

        let local_var_uri_str = format!("{}_plugins/_knn/warmup/{index}", local_var_configuration.base_path, index=index);
        let mut local_var_req_builder = local_var_client.request(reqwest::Method::GET, local_var_uri_str.as_str());


    if let Some(ref local_var_str) = pretty {
        local_var_req_builder = local_var_req_builder.query(&[("pretty", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = filter_path {
        local_var_req_builder = local_var_req_builder.query(&[("filter_path", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = error_trace {
        local_var_req_builder = local_var_req_builder.query(&[("error_trace", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = human {
        local_var_req_builder = local_var_req_builder.query(&[("human", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source {
        local_var_req_builder = local_var_req_builder.query(&[("source", &local_var_str.to_string())]);
    }







        let local_var_req = local_var_req_builder.build()?;
        let local_var_resp = local_var_client.execute(local_var_req).await?;

        let local_var_status = local_var_resp.status();
        let local_var_content = local_var_resp.text().await?;

        if !local_var_status.is_client_error() && !local_var_status.is_server_error() {
            
            serde_json::from_str(&local_var_content).map_err(Error::from)
            
            
        } else {
            let local_var_error = ResponseContent {
                status: local_var_status,
                content: local_var_content,
            };
            Err(Error::ApiError(local_var_error))
        }
    }///
      /// Use an OpenSearch query to search for models in the index.
    async fn search_models(&self, params: SearchModelsParams) -> Result<crate::core::search::ResponseBody, Error> {
        let SearchModelsParams {
            search_models,
            scroll,
            timeout,
            suggest_size,
            allow_partial_search_results,
            track_total_hits,
            rest_total_hits_as_int,
            ccs_minimize_roundtrips,
            source_excludes,
            source_includes,
            docvalue_fields,
            error_trace,
            filter_path,
            human,
            pretty,
            routing,
            sort,
            source,
            stats,
            stored_fields,
            size,
            q,
            search_type,
            expand_wildcards,
            request_cache,
            suggest_mode,
            preference,
            typed_keys,
            lenient,
            explain,
            seq_no_primary_term,
            analyze_wildcard,
            suggest_field,
            from,
            analyzer,
            default_operator,
            df,
            terminate_after,
            max_concurrent_shard_requests,
            batched_reduce_size,
            suggest_text,
            pre_filter_shard_size,
            ignore_unavailable,
            ignore_throttled,
            track_scores,
            allow_no_indices,
            version,
        } = params;
    
        let local_var_configuration = &self.configuration;

        let local_var_client = &local_var_configuration.client;

        let local_var_uri_str = format!("{}_plugins/_knn/models/_search", local_var_configuration.base_path);
        let mut local_var_req_builder = local_var_client.request(reqwest::Method::POST, local_var_uri_str.as_str());


    if let Some(ref local_var_str) = pre_filter_shard_size {
        local_var_req_builder = local_var_req_builder.query(&[("pre_filter_shard_size", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = timeout {
        local_var_req_builder = local_var_req_builder.query(&[("timeout", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = stats {
        local_var_req_builder = match "multi" {
            "multi" => local_var_req_builder.query(&local_var_str.into_iter().map(|p| ("stats".to_owned(), p.to_string())).collect::<Vec<(std::string::String, std::string::String)>>()),
            _ => local_var_req_builder.query(&[("stats", &local_var_str.into_iter().map(|p| p.to_string()).collect::<Vec<String>>().join(",").to_string())]),
        };
    }
    if let Some(ref local_var_str) = human {
        local_var_req_builder = local_var_req_builder.query(&[("human", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = ignore_throttled {
        local_var_req_builder = local_var_req_builder.query(&[("ignore_throttled", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = analyzer {
        local_var_req_builder = local_var_req_builder.query(&[("analyzer", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = allow_no_indices {
        local_var_req_builder = local_var_req_builder.query(&[("allow_no_indices", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = preference {
        local_var_req_builder = local_var_req_builder.query(&[("preference", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = seq_no_primary_term {
        local_var_req_builder = local_var_req_builder.query(&[("seq_no_primary_term", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = error_trace {
        local_var_req_builder = local_var_req_builder.query(&[("error_trace", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = track_scores {
        local_var_req_builder = local_var_req_builder.query(&[("track_scores", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = allow_partial_search_results {
        local_var_req_builder = local_var_req_builder.query(&[("allow_partial_search_results", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = filter_path {
        local_var_req_builder = local_var_req_builder.query(&[("filter_path", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = batched_reduce_size {
        local_var_req_builder = local_var_req_builder.query(&[("batched_reduce_size", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = ccs_minimize_roundtrips {
        local_var_req_builder = local_var_req_builder.query(&[("ccs_minimize_roundtrips", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = routing {
        local_var_req_builder = local_var_req_builder.query(&[("routing", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = docvalue_fields {
        local_var_req_builder = match "multi" {
            "multi" => local_var_req_builder.query(&local_var_str.into_iter().map(|p| ("docvalue_fields".to_owned(), p.to_string())).collect::<Vec<(std::string::String, std::string::String)>>()),
            _ => local_var_req_builder.query(&[("docvalue_fields", &local_var_str.into_iter().map(|p| p.to_string()).collect::<Vec<String>>().join(",").to_string())]),
        };
    }
    if let Some(ref local_var_str) = suggest_size {
        local_var_req_builder = local_var_req_builder.query(&[("suggest_size", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = search_type {
        local_var_req_builder = local_var_req_builder.query(&[("search_type", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = suggest_text {
        local_var_req_builder = local_var_req_builder.query(&[("suggest_text", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = suggest_field {
        local_var_req_builder = local_var_req_builder.query(&[("suggest_field", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source_includes {
        local_var_req_builder = match "multi" {
            "multi" => local_var_req_builder.query(&local_var_str.into_iter().map(|p| ("source_includes".to_owned(), p.to_string())).collect::<Vec<(std::string::String, std::string::String)>>()),
            _ => local_var_req_builder.query(&[("source_includes", &local_var_str.into_iter().map(|p| p.to_string()).collect::<Vec<String>>().join(",").to_string())]),
        };
    }
    if let Some(ref local_var_str) = terminate_after {
        local_var_req_builder = local_var_req_builder.query(&[("terminate_after", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = typed_keys {
        local_var_req_builder = local_var_req_builder.query(&[("typed_keys", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = max_concurrent_shard_requests {
        local_var_req_builder = local_var_req_builder.query(&[("max_concurrent_shard_requests", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = analyze_wildcard {
        local_var_req_builder = local_var_req_builder.query(&[("analyze_wildcard", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = stored_fields {
        local_var_req_builder = match "multi" {
            "multi" => local_var_req_builder.query(&local_var_str.into_iter().map(|p| ("stored_fields".to_owned(), p.to_string())).collect::<Vec<(std::string::String, std::string::String)>>()),
            _ => local_var_req_builder.query(&[("stored_fields", &local_var_str.into_iter().map(|p| p.to_string()).collect::<Vec<String>>().join(",").to_string())]),
        };
    }
    if let Some(ref local_var_str) = ignore_unavailable {
        local_var_req_builder = local_var_req_builder.query(&[("ignore_unavailable", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = pretty {
        local_var_req_builder = local_var_req_builder.query(&[("pretty", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source_excludes {
        local_var_req_builder = match "multi" {
            "multi" => local_var_req_builder.query(&local_var_str.into_iter().map(|p| ("source_excludes".to_owned(), p.to_string())).collect::<Vec<(std::string::String, std::string::String)>>()),
            _ => local_var_req_builder.query(&[("source_excludes", &local_var_str.into_iter().map(|p| p.to_string()).collect::<Vec<String>>().join(",").to_string())]),
        };
    }
    if let Some(ref local_var_str) = request_cache {
        local_var_req_builder = local_var_req_builder.query(&[("request_cache", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = scroll {
        local_var_req_builder = local_var_req_builder.query(&[("scroll", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = explain {
        local_var_req_builder = local_var_req_builder.query(&[("explain", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = default_operator {
        local_var_req_builder = local_var_req_builder.query(&[("default_operator", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = sort {
        local_var_req_builder = match "multi" {
            "multi" => local_var_req_builder.query(&local_var_str.into_iter().map(|p| ("sort".to_owned(), p.to_string())).collect::<Vec<(std::string::String, std::string::String)>>()),
            _ => local_var_req_builder.query(&[("sort", &local_var_str.into_iter().map(|p| p.to_string()).collect::<Vec<String>>().join(",").to_string())]),
        };
    }
    if let Some(ref local_var_str) = rest_total_hits_as_int {
        local_var_req_builder = local_var_req_builder.query(&[("rest_total_hits_as_int", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = expand_wildcards {
        local_var_req_builder = local_var_req_builder.query(&[("expand_wildcards", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = size {
        local_var_req_builder = local_var_req_builder.query(&[("size", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = suggest_mode {
        local_var_req_builder = local_var_req_builder.query(&[("suggest_mode", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = version {
        local_var_req_builder = local_var_req_builder.query(&[("version", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = source {
        local_var_req_builder = local_var_req_builder.query(&[("source", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = q {
        local_var_req_builder = local_var_req_builder.query(&[("q", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = from {
        local_var_req_builder = local_var_req_builder.query(&[("from", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = track_total_hits {
        local_var_req_builder = local_var_req_builder.query(&[("track_total_hits", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = df {
        local_var_req_builder = local_var_req_builder.query(&[("df", &local_var_str.to_string())]);
    }
    if let Some(ref local_var_str) = lenient {
        local_var_req_builder = local_var_req_builder.query(&[("lenient", &local_var_str.to_string())]);
    }






    local_var_req_builder = local_var_req_builder.json(&search_models);

        let local_var_req = local_var_req_builder.build()?;
        let local_var_resp = local_var_client.execute(local_var_req).await?;

        let local_var_status = local_var_resp.status();
        let local_var_content = local_var_resp.text().await?;

        if !local_var_status.is_client_error() && !local_var_status.is_server_error() {
            
            serde_json::from_str(&local_var_content).map_err(Error::from)
            
            
        } else {
            let local_var_error = ResponseContent {
                status: local_var_status,
                content: local_var_content,
            };
            Err(Error::ApiError(local_var_error))
        }
    }
}
















